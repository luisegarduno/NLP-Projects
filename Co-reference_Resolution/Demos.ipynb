{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ee0b669",
   "metadata": {},
   "source": [
    "# Demos for NeuralCoref & OpenIE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7bea96",
   "metadata": {},
   "source": [
    "## 1. NeuralCoref Example\n",
    "- State-of-the-art coreference resolution based on neural nets and spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa6840c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Ex.1] My sister has a dog. She loves him. \n",
      "==>  [My sister: [My sister, She], a dog: [a dog, him]]\n",
      "\n",
      "[Ex.2] Angela lives in Boston. She is quite happy in that city.\n",
      "==>  Angela: [Angela, She]\n",
      "==>  Boston: [Boston, that city]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import neuralcoref\n",
    "\n",
    "nlp = spacy.load('en')\n",
    "neuralcoref.add_to_pipe(nlp)\n",
    "\n",
    "ex_1 = 'My sister has a dog. She loves him.'\n",
    "ex_2 = 'Angela lives in Boston. She is quite happy in that city.'\n",
    "\n",
    "doc1 = nlp(ex_1)\n",
    "print(\"[Ex.1]\", ex_1, \"\\n==> \", doc1._.coref_clusters)\n",
    "\n",
    "print(\"\\n[Ex.2]\", ex_2)\n",
    "doc2 = nlp(ex_2)\n",
    "for ent in doc2.ents:\n",
    "    print(\"==> \", ent._.coref_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3f0347e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster: [John, he]\n",
      "\n",
      "John have dinner today and he enjoyed it.  -->  John have dinner today and John enjoyed it.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import neuralcoref\n",
    "\n",
    "nlp = spacy.load('en')\n",
    "neuralcoref.add_to_pipe(nlp)\n",
    "\n",
    "original_str = u'John have dinner today and he enjoyed it.'\n",
    "\n",
    "doc = nlp(original_str)\n",
    "\n",
    "word_1 = doc._.coref_clusters[0].mentions[-1]\n",
    "word_2 = doc._.coref_clusters[0].mentions[-1]._.coref_cluster.main\n",
    "\n",
    "print(\"Cluster:\", doc._.coref_clusters[0].mentions)\n",
    "\n",
    "new_str = original_str.replace(str(word_1), str(word_2))\n",
    "print(\"\\n\" + original_str, \" --> \", new_str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88fa7e4",
   "metadata": {},
   "source": [
    "## 2. Stanford's OpenIE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5ce3e2",
   "metadata": {},
   "source": [
    "### &nbsp;&nbsp;&nbsp; OpenIE - Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d1eff71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================> INPUT <=======================\n",
      "\n",
      "John have dinner today and he enjoyed it.\n",
      "\n",
      "\n",
      "=======================> OUTPUT <=======================\n",
      "Starting server with command: java -Xmx8G -cp /home/blurry/.stanfordnlp_resources/stanford-corenlp-4.1.0/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 60000 -threads 5 -maxCharLength 100000 -quiet True -serverProperties corenlp_server-e28fb87ba168424d.props -preload openie\n",
      "\n",
      "==>  {'subject': 'he', 'relation': 'enjoyed', 'object': 'it'}\n",
      "==>  {'subject': 'John', 'relation': 'have dinner at_time', 'object': 'today'}\n"
     ]
    }
   ],
   "source": [
    "from openie import StanfordOpenIE\n",
    "\n",
    "with StanfordOpenIE() as client:\n",
    "    i=1\n",
    "    \n",
    "    txt = original_str\n",
    "    print(\"=======================> INPUT <=======================\\n\\n%s\" % txt)\n",
    "    \n",
    "    print(\"\\n\\n=======================> OUTPUT <=======================\")\n",
    "    for triple in client.annotate(txt):\n",
    "        if i: i=0; print();\n",
    "        print(\"==> \", triple)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02e0d41",
   "metadata": {},
   "source": [
    "\n",
    "------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "### &nbsp;&nbsp;&nbsp; OpenIE - Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe1ed723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================> INPUT <=======================\n",
      "\n",
      "John have dinner today and he enjoyed it.\n",
      "\n",
      "\n",
      "=======================> OUTPUT <=======================\n",
      "Document: ID=ex.txt (1 sentences, 9 tokens)\n",
      "\n",
      "Sentence #1 (9 tokens):\n",
      "John have dinner today and he enjoyed it.\n",
      "\n",
      "Tokens:\n",
      "[Text=John CharacterOffsetBegin=0 CharacterOffsetEnd=4 PartOfSpeech=NNP Lemma=John NamedEntityTag=PERSON]\n",
      "[Text=have CharacterOffsetBegin=5 CharacterOffsetEnd=9 PartOfSpeech=VBP Lemma=have NamedEntityTag=O]\n",
      "[Text=dinner CharacterOffsetBegin=10 CharacterOffsetEnd=16 PartOfSpeech=NN Lemma=dinner NamedEntityTag=O]\n",
      "[Text=today CharacterOffsetBegin=17 CharacterOffsetEnd=22 PartOfSpeech=NN Lemma=today NamedEntityTag=DATE NormalizedNamedEntityTag=THIS P1D Timex=<TIMEX3 alt_value=\"THIS P1D\" anchorTimeID=\"t0\" temporalFunction=\"true\" tid=\"t1\" type=\"DATE\" valueFromFunction=\"tf0\">today</TIMEX3>]\n",
      "[Text=and CharacterOffsetBegin=23 CharacterOffsetEnd=26 PartOfSpeech=CC Lemma=and NamedEntityTag=O]\n",
      "[Text=he CharacterOffsetBegin=27 CharacterOffsetEnd=29 PartOfSpeech=PRP Lemma=he NamedEntityTag=O]\n",
      "[Text=enjoyed CharacterOffsetBegin=30 CharacterOffsetEnd=37 PartOfSpeech=VBD Lemma=enjoy NamedEntityTag=O]\n",
      "[Text=it CharacterOffsetBegin=38 CharacterOffsetEnd=40 PartOfSpeech=PRP Lemma=it NamedEntityTag=O]\n",
      "[Text=. CharacterOffsetBegin=40 CharacterOffsetEnd=41 PartOfSpeech=. Lemma=. NamedEntityTag=O]\n",
      "\n",
      "Dependency Parse (enhanced plus plus dependencies):\n",
      "root(ROOT-0, have-2)\n",
      "nsubj(have-2, John-1)\n",
      "obj(have-2, dinner-3)\n",
      "obl:tmod(have-2, today-4)\n",
      "cc(enjoyed-7, and-5)\n",
      "nsubj(enjoyed-7, he-6)\n",
      "conj:and(have-2, enjoyed-7)\n",
      "obj(enjoyed-7, it-8)\n",
      "punct(have-2, .-9)\n",
      "\n",
      "Extracted the following NER entity mentions:\n",
      "John\tPERSON\tPERSON:0.9861268552545607\n",
      "today\tDATE\tDATE:-1.0\n",
      "he\tPERSON\t-\n",
      "\n",
      "Coreference set:\n",
      "\t(1,6,[6,7]) -> (1,1,[1,2]), that is: \"he\" -> \"John\"\n",
      "\n",
      "Coreference set:\n",
      "\t(1,8,[8,9]) -> (1,3,[3,4]), that is: \"it\" -> \"dinner\"\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "echo -e \"=======================> INPUT <=======================\\n\"; cat ex.txt\n",
    "\n",
    "#java -cp \"stanford-corenlp-4.2.0/*\" -Xmx5g edu.stanford.nlp.pipeline.StanfordCoreNLP -file ex.txt;\n",
    "\n",
    "echo -e \"\\n\\n=======================> OUTPUT <=======================\"; cat ex.txt.out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
